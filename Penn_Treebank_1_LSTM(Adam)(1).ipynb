{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Penn_Treebank_1_LSTM(Adam).ipynb","provenance":[{"file_id":"18_0qHuK5tvwAfyVVoruWVta1pxBzDQxC","timestamp":1590418257980}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"S6lyfG8jZt1b","colab_type":"text"},"source":["# Init"]},{"cell_type":"code","metadata":{"id":"usrX2f-qZvi5","colab_type":"code","outputId":"540c9309-d957-4889-8d7f-99035043bf03","executionInfo":{"status":"ok","timestamp":1590418331265,"user_tz":-60,"elapsed":7723,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"15439544951905613244"}},"colab":{"base_uri":"https://localhost:8080/","height":168}},"source":["# Execute this code block to install dependencies when running on colab\n","try:\n","    import torch\n","except:\n","    from os.path import exists\n","    from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","    platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","    cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n","    accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n","\n","    !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl torchvision\n","\n","try: \n","    import torchbearer\n","except:\n","    !pip install torchbearer"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting torchbearer\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e9/4049a47dd2e5b6346a2c5d215b0c67dce814afbab1cd54ce024533c4834e/torchbearer-0.5.3-py3-none-any.whl (138kB)\n","\r\u001b[K     |██▍                             | 10kB 19.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 40kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 61kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 81kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 3.5MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchbearer) (1.18.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchbearer) (4.41.1)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from torchbearer) (1.5.0+cu101)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->torchbearer) (0.16.0)\n","Installing collected packages: torchbearer\n","Successfully installed torchbearer-0.5.3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RQV9LbVMZ5NG","colab_type":"text"},"source":["# Prepare Penn Treebank dataset"]},{"cell_type":"code","metadata":{"id":"KhEeh6x8Z9eE","colab_type":"code","colab":{}},"source":["# automatically reload external modules if they change\n","%load_ext autoreload\n","%autoreload 2\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torchtext import data\n","from torchtext import vocab\n","from torchtext import datasets\n","\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","from tqdm import tqdm"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NWmejPqvd93t","colab_type":"code","outputId":"90b8cc22-9d37-4b7b-c529-4fc196d58499","executionInfo":{"status":"ok","timestamp":1590418807238,"user_tz":-60,"elapsed":483685,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"15439544951905613244"}},"colab":{"base_uri":"https://localhost:8080/","height":168}},"source":["tokenize = lambda x: x.split()\n","TEXT = data.Field(sequential = True, tokenize = tokenize, lower = True, batch_first = True)\n","train_dataset, val_dataset, test_dataset = datasets.PennTreebank.splits(TEXT)\n","TEXT.build_vocab(train_dataset, vectors=vocab.GloVe(name='6B', dim=300))\n","\n","vocab_size = len(TEXT.vocab)\n","word_embeddings = TEXT.vocab.vectors\n","print(vocab_size)\n","print(word_embeddings.size())\n","embeddings_length = 300\n","hidden_size = 256\n","batch_size = 32"],"execution_count":3,"outputs":[{"output_type":"stream","text":["downloading ptb.train.txt\n"],"name":"stdout"},{"output_type":"stream","text":["ptb.train.txt: 5.10MB [00:00, 57.5MB/s]                   \n"],"name":"stderr"},{"output_type":"stream","text":["downloading ptb.valid.txt\n"],"name":"stdout"},{"output_type":"stream","text":["ptb.valid.txt: 400kB [00:00, 12.6MB/s]                   \n"],"name":"stderr"},{"output_type":"stream","text":["downloading ptb.test.txt\n"],"name":"stdout"},{"output_type":"stream","text":["ptb.test.txt: 450kB [00:00, 10.7MB/s]                   \n",".vector_cache/glove.6B.zip: 862MB [06:27, 2.22MB/s]                          \n","100%|█████████▉| 399601/400000 [00:54<00:00, 7447.95it/s]"],"name":"stderr"},{"output_type":"stream","text":["10001\n","torch.Size([10001, 300])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5Hl-iXexfSWl","colab_type":"code","colab":{}},"source":["train_iter, val_iter, test_iter = data.BPTTIterator.splits((train_dataset, val_dataset, test_dataset), batch_size = 32, bptt_len=30, repeat=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wPLZIYqKhvTF","colab_type":"code","colab":{}},"source":["class LstmLangModel(nn.Module):\n","   def __init__(self, batch_size, hidden_size, vocab_size, embeddings_length, weights):\n","       super(LstmLangModel, self).__init__()\n","       self.batch_size = batch_size\n","       self.hidden_size = hidden_size\n","       self.vocab_size = vocab_size\n","       self.embed = nn.Embedding(vocab_size, embeddings_length)\n","       self.embed.weight.data.copy_(weights)\n","       self.lstm = nn.LSTM(embeddings_length, hidden_size, batch_first=True)\n","       self.fc = nn.Linear(hidden_size, vocab_size)\n","   def forward(self, x, h):\n","       x = self.embed(x)\n","       output_seq, (h, c) = self.lstm(x, h)\n","       out = output_seq.reshape(output_seq.size(0)*output_seq.size(1), output_seq.size(2))\n","       out = self.fc(out)\n","       return out, (h, c)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ySgb_BtfkbjZ","colab_type":"code","outputId":"09cbfd09-7f31-437c-cb66-9fa94320cf84","executionInfo":{"status":"ok","timestamp":1590418807240,"user_tz":-60,"elapsed":483676,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"15439544951905613244"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["vocab_size = len(TEXT.vocab)\n","word_embeddings = TEXT.vocab.vectors\n","print(vocab_size)\n","print(word_embeddings.size())\n","embeddings_length = 300\n","hidden_size = 256\n","batch_size = 32"],"execution_count":6,"outputs":[{"output_type":"stream","text":["10001\n","torch.Size([10001, 300])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O7h9zfUYkFEc","colab_type":"code","outputId":"417de557-7a72-4d41-cc87-3907e35f7709","executionInfo":{"status":"ok","timestamp":1590418807391,"user_tz":-60,"elapsed":483820,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"15439544951905613244"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["model = LstmLangModel(batch_size, hidden_size, vocab_size, embeddings_length, word_embeddings)\n","model.eval()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LstmLangModel(\n","  (embed): Embedding(10001, 300)\n","  (lstm): LSTM(300, 256, batch_first=True)\n","  (fc): Linear(in_features=256, out_features=10001, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"k6CWQqenmQ56","colab_type":"text"},"source":["# Torchbear Section"]},{"cell_type":"code","metadata":{"id":"TtOu1hMbjzbZ","colab_type":"code","outputId":"ea062bfa-5c4a-4fc2-9f7c-b7b8d225c40f","executionInfo":{"status":"error","timestamp":1590419018795,"user_tz":-60,"elapsed":695217,"user":{"displayName":"Eric Lee","photoUrl":"","userId":"15439544951905613244"}},"colab":{"base_uri":"https://localhost:8080/","height":505}},"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","net_lstm = LstmLangModel(batch_size, hidden_size, vocab_size, embeddings_length, word_embeddings)\n","net_lstm = net_lstm.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optim = torch.optim.Adam(filter(lambda p: p.requires_grad, net_lstm.parameters()))\n","num_epochs = 100\n","epoch_list = []\n","train_loss_lstm_list = []\n","train_perp_lstm_list = []\n","\n","def detach(states):\n","   return [state.detach() for state in states]\n","\n","for epoch in range(num_epochs):\n","   train_loss = 0\n","   states = (torch.zeros(1, batch_size, hidden_size).to(device),\n","             torch.zeros(1, batch_size, hidden_size).to(device))\n","   net_lstm.train()\n","\n","   for i, batch in enumerate(train_iter):\n","       text = batch.text.to(device)\n","       labels = batch.target.to(device)\n","       text = text.permute(1, 0)\n","       labels = labels.permute(1, 0)\n","\n","       optim.zero_grad()\n","       states = detach(states)\n","       outputs, states = net_lstm(text, states)\n","       loss = criterion(outputs, labels.reshape(-1))\n","       train_loss += loss.item()\n","       loss.backward()\n","       optim.step()\n","   avg_train_loss = train_loss / len(train_iter)\n","   perplexity = np.exp(avg_train_loss)\n","   print('Epoch [{}/{}], Loss: {:.4f}, Perplexity: {:5.2f}'.format(epoch + 1, num_epochs, avg_train_loss, perplexity))\n","   train_loss_lstm_list.append(avg_train_loss)\n","   train_perp_lstm_list.append(perplexity)\n","\n","   if epoch % 100 == 0:\n","       torch.save(net_lstm.state_dict(), r\"./LSTM_\" + str(epoch) + r\".pth\")\n","   \n","   if epoch == num_epochs - 1:\n","       torch.save(net_lstm.state_dict(), r\"./LSTM_\" + str(epoch) + r\".pth\")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["\r100%|█████████▉| 399601/400000 [01:10<00:00, 7447.95it/s]"],"name":"stderr"},{"output_type":"stream","text":["Epoch [1/100], Loss: 5.7928, Perplexity: 327.94\n","Epoch [2/100], Loss: 5.0672, Perplexity: 158.73\n","Epoch [3/100], Loss: 4.7651, Perplexity: 117.34\n","Epoch [4/100], Loss: 4.5422, Perplexity: 93.90\n","Epoch [5/100], Loss: 4.3621, Perplexity: 78.42\n","Epoch [6/100], Loss: 4.2096, Perplexity: 67.33\n","Epoch [7/100], Loss: 4.0768, Perplexity: 58.96\n","Epoch [8/100], Loss: 3.9579, Perplexity: 52.35\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-ac39f63804a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m        \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m        \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m        \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m    \u001b[0mavg_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}